{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "DataIngestionArtifact = namedtuple(\"DataIngestionArtifact\",\n",
    "                                   [\"feature_store_file_path\", \"metadata_file_path\", \"download_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DI = DataIngestionArtifact(\"path_for_data_ingestion\", \"path_for_metadata_file\", \"path_for_download_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'path_for_data_ingestion'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DI[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'path_for_metadata_file'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DI.metadata_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('feature_store_file_path', 'metadata_file_path', 'download_dir')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DI._fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from finance_complaint.config.spark_manager import spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/captain/INeuron/Industry Ready/Finance Project/Repo/finance-complaint/finance_artifact/data_ingestion/feature_store/finance_complaint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataset = spark_session.read.parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company',\n",
       " 'company_public_response',\n",
       " 'company_response',\n",
       " 'complaint_id',\n",
       " 'complaint_what_happened',\n",
       " 'consumer_consent_provided',\n",
       " 'consumer_disputed',\n",
       " 'date_received',\n",
       " 'date_sent_to_company',\n",
       " 'issue',\n",
       " 'product',\n",
       " 'state',\n",
       " 'sub_issue',\n",
       " 'sub_product',\n",
       " 'submitted_via',\n",
       " 'tags',\n",
       " 'timely',\n",
       " 'zip_code']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[company: string, company_public_response: string, company_response: string, complaint_id: string, complaint_what_happened: string, consumer_consent_provided: string, consumer_disputed: string, date_received: string, date_sent_to_company: string, issue: string, product: string, state: string, sub_issue: string, sub_product: string, submitted_via: string, tags: string, timely: string, zip_code: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.select(col('state').alias(f'g_state')).groupby(f'g_state').count().withColumn('freq_count', col('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|             g_state|freq_count|\n",
      "+--------------------+----------+\n",
      "|UNITED STATES MIN...|        29|\n",
      "|                  SC|      8868|\n",
      "|                  AZ|      7988|\n",
      "|                  LA|      7880|\n",
      "|                  MN|      2912|\n",
      "|                  NJ|     13640|\n",
      "|                  DC|      1585|\n",
      "|                  OR|      1821|\n",
      "|                  VA|     10562|\n",
      "|                null|       582|\n",
      "|                  RI|       831|\n",
      "|                  KY|      1969|\n",
      "|                  WY|       187|\n",
      "|                  NH|       514|\n",
      "|                  MI|     10549|\n",
      "|                  NV|      6869|\n",
      "|                  WI|      3417|\n",
      "|                  ID|       520|\n",
      "|                  CA|     43178|\n",
      "|                  CT|      3236|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(g_state='UNITED STATES MINOR OUTLYING ISLANDS', freq_count=29),\n",
       " Row(g_state='SC', freq_count=8868),\n",
       " Row(g_state='AZ', freq_count=7988),\n",
       " Row(g_state='LA', freq_count=7880),\n",
       " Row(g_state='MN', freq_count=2912),\n",
       " Row(g_state='NJ', freq_count=13640),\n",
       " Row(g_state='DC', freq_count=1585),\n",
       " Row(g_state='OR', freq_count=1821),\n",
       " Row(g_state='VA', freq_count=10562),\n",
       " Row(g_state=None, freq_count=582),\n",
       " Row(g_state='RI', freq_count=831),\n",
       " Row(g_state='KY', freq_count=1969),\n",
       " Row(g_state='WY', freq_count=187),\n",
       " Row(g_state='NH', freq_count=514),\n",
       " Row(g_state='MI', freq_count=10549),\n",
       " Row(g_state='NV', freq_count=6869),\n",
       " Row(g_state='WI', freq_count=3417),\n",
       " Row(g_state='ID', freq_count=520),\n",
       " Row(g_state='CA', freq_count=43178),\n",
       " Row(g_state='CT', freq_count=3236),\n",
       " Row(g_state='NE', freq_count=607),\n",
       " Row(g_state='MT', freq_count=428),\n",
       " Row(g_state='NC', freq_count=16768),\n",
       " Row(g_state='VT', freq_count=182),\n",
       " Row(g_state='MD', freq_count=11770),\n",
       " Row(g_state='DE', freq_count=2614),\n",
       " Row(g_state='MO', freq_count=6053),\n",
       " Row(g_state='VI', freq_count=71),\n",
       " Row(g_state='IL', freq_count=19785),\n",
       " Row(g_state='ME', freq_count=501),\n",
       " Row(g_state='GU', freq_count=11),\n",
       " Row(g_state='WA', freq_count=3651),\n",
       " Row(g_state='ND', freq_count=241),\n",
       " Row(g_state='MS', freq_count=5042),\n",
       " Row(g_state='AL', freq_count=10266),\n",
       " Row(g_state='IN', freq_count=4737),\n",
       " Row(g_state='AE', freq_count=120),\n",
       " Row(g_state='OH', freq_count=10392),\n",
       " Row(g_state='TN', freq_count=8357),\n",
       " Row(g_state='NM', freq_count=917),\n",
       " Row(g_state='IA', freq_count=1133),\n",
       " Row(g_state='PA', freq_count=23224),\n",
       " Row(g_state='SD', freq_count=225),\n",
       " Row(g_state='NY', freq_count=26086),\n",
       " Row(g_state='TX', freq_count=46610),\n",
       " Row(g_state='WV', freq_count=543),\n",
       " Row(g_state='GA', freq_count=36286),\n",
       " Row(g_state='MA', freq_count=4586),\n",
       " Row(g_state='KS', freq_count=1360),\n",
       " Row(g_state='FL', freq_count=51288),\n",
       " Row(g_state='CO', freq_count=3486),\n",
       " Row(g_state='AK', freq_count=367),\n",
       " Row(g_state='AR', freq_count=2763),\n",
       " Row(g_state='OK', freq_count=2301),\n",
       " Row(g_state='PR', freq_count=502),\n",
       " Row(g_state='AP', freq_count=54),\n",
       " Row(g_state='UT', freq_count=1328),\n",
       " Row(g_state='HI', freq_count=718),\n",
       " Row(g_state='AA', freq_count=2),\n",
       " Row(g_state='AS', freq_count=6)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(g_state='UNITED STATES MINOR OUTLYING ISLANDS', freq_count=29)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNITED STATES MINOR OUTLYING ISLANDS'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()[0].g_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()[0].freq_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|             g_state|freq_count|\n",
      "+--------------------+----------+\n",
      "|UNITED STATES MIN...|        29|\n",
      "|                  SC|      8868|\n",
      "|                  AZ|      7988|\n",
      "|                  LA|      7880|\n",
      "|                  MN|      2912|\n",
      "|                  NJ|     13640|\n",
      "|                  DC|      1585|\n",
      "|                  OR|      1821|\n",
      "|                  VA|     10562|\n",
      "|                null|       582|\n",
      "|                  RI|       831|\n",
      "|                  KY|      1969|\n",
      "|                  WY|       187|\n",
      "|                  NH|       514|\n",
      "|                  MI|     10549|\n",
      "|                  NV|      6869|\n",
      "|                  WI|      3417|\n",
      "|                  ID|       520|\n",
      "|                  CA|     43178|\n",
      "|                  CT|      3236|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_session.createDataFrame(df.collect()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark Data Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.transformer import Transformer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# Read data as pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SquareTransformer(Transformer):\n",
    "    def __init__(self):\n",
    "        super(SquareTransformer, self).__init__()\n",
    "    \n",
    "    def setInputCol(self, inputCol: str) -> None:\n",
    "        self.inputCol = inputCol\n",
    "        \n",
    "    def setOutputCol(self, outputCol: str) -> None:\n",
    "        self.outputCol = outputCol\n",
    "        \n",
    "    def transform(self, dataset: pyspark.sql.DataFrame) -> pyspark.sql.DataFrame:\n",
    "        square = lambda x: x**2\n",
    "        squared_udf = udf(square, DoubleType())\n",
    "        return dataset.withColumn(self.outputCol, squared_udf(self.inputCol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SquareTransformer class\n",
    "square_transformer = SquareTransformer()\n",
    "\n",
    "# Set the input and output columns for the transformer\n",
    "square_transformer.setInputCol('col1')\n",
    "square_transformer.setOutputCol('squared')\n",
    "\n",
    "# Create a PySpark pipeline and add the square_transformer to it\n",
    "pipeline = Pipeline(stages=[square_transformer])\n",
    "\n",
    "# Fit the pipeline to a dataset and apply the transformation\n",
    "transformed_dataset = pipeline.fit(dataset).transform(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0380fd6c350aea6a25a1d8cd1c4716a7b06f5b6629438eba3330436b8aff04df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
