{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "DataIngestionArtifact = namedtuple(\"DataIngestionArtifact\",\n",
    "                                   [\"feature_store_file_path\", \"metadata_file_path\", \"download_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DI = DataIngestionArtifact(\"path_for_data_ingestion\", \"path_for_metadata_file\", \"path_for_download_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'path_for_data_ingestion'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DI[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'path_for_metadata_file'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DI.metadata_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('feature_store_file_path', 'metadata_file_path', 'download_dir')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DI._fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data as pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.transformer import Transformer\n",
    "\n",
    "class SquareTransformer(Transformer):\n",
    "    def __init__(self):\n",
    "        super(SquareTransformer, self).__init__()\n",
    "    \n",
    "    def setInputCol(self, inputCol: str) -> None:\n",
    "        self.inputCol = inputCol\n",
    "        \n",
    "    def setOutputCol(self, outputCol: str) -> None:\n",
    "        self.outputCol = outputCol\n",
    "        \n",
    "    def transform(self, dataset: pyspark.sql.DataFrame) -> pyspark.sql.DataFrame:\n",
    "        square = lambda x: x**2\n",
    "        squared_udf = F.udf(square, DoubleType())\n",
    "        return dataset.withColumn(self.outputCol, squared_udf(self.inputCol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SquareTransformer class\n",
    "square_transformer = SquareTransformer()\n",
    "\n",
    "# Set the input and output columns for the transformer\n",
    "square_transformer.setInputCol('col1')\n",
    "square_transformer.setOutputCol('squared')\n",
    "\n",
    "# Create a PySpark pipeline and add the square_transformer to it\n",
    "pipeline = Pipeline(stages=[square_transformer])\n",
    "\n",
    "# Fit the pipeline to a dataset and apply the transformation\n",
    "transformed_dataset = pipeline.fit(dataset).transform(dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0380fd6c350aea6a25a1d8cd1c4716a7b06f5b6629438eba3330436b8aff04df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
